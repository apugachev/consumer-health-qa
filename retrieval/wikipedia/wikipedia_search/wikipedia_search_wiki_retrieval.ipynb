{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df726bc5-e065-4a3a-98f5-86a9262f4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "from progressbar import progressbar as pb\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "from wikipedia.exceptions import DisambiguationError\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../experiments/\") # use utils\n",
    "\n",
    "from utils import normalize_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab8c595-c77e-48fc-a091-473e17766906",
   "metadata": {},
   "source": [
    "## Obtain wiki paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2ce290-e08e-4aaa-a39a-a29b07a2b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K_PER_QUERY = 10 # maximum number of paragraphs that we are looking for one query\n",
    "TOP_K_PER_ARTICLE = 2 # maximum number of paragraphs we take from one wiki article\n",
    "\n",
    "def get_suitable_paragraphs(query, tokens_to_find, content, serp_pos, title, title_common_tokens, top_k_per_article=TOP_K_PER_ARTICLE):\n",
    "    \n",
    "    paragraphs = content.split(\"\\n\")\n",
    "    \n",
    "    result = {key: [] for key in [\n",
    "        \"query_processed\",\n",
    "        \"article_title\", \"paragraph\", \"serp_position\", \n",
    "        \"title_common_tokens\", \"num_title_common_tokens\", \n",
    "        \"tokens_to_find\", \n",
    "        \"paragraph_common_tokens\", \"num_paragraph_common_tokens\",\n",
    "        \"paragraph_number_in_article\"\n",
    "    ]}\n",
    "    \n",
    "    for i, p in enumerate(paragraphs):\n",
    "        \n",
    "        if not p or p.endswith(\"==\"):\n",
    "            continue\n",
    "        \n",
    "        normed_p = normalize_text(p)\n",
    "        p_tokens = set(normed_p.split())\n",
    "        \n",
    "        paragraph_common_tokens = tokens_to_find & p_tokens\n",
    "        \n",
    "        if paragraph_common_tokens:\n",
    "            result[\"query_processed\"].append(query)\n",
    "            result[\"article_title\"].append(title)\n",
    "            result[\"paragraph\"].append(p)\n",
    "            result[\"serp_position\"].append(serp_pos)\n",
    "            result[\"title_common_tokens\"].append(list(title_common_tokens))\n",
    "            result[\"num_title_common_tokens\"].append(len(title_common_tokens))\n",
    "            result[\"tokens_to_find\"].append(list(tokens_to_find))\n",
    "            result[\"paragraph_common_tokens\"].append(list(paragraph_common_tokens))\n",
    "            result[\"num_paragraph_common_tokens\"].append(len(paragraph_common_tokens))\n",
    "            result[\"paragraph_number_in_article\"].append(i)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_paragraphs(query, top_k_per_query=TOP_K_PER_QUERY, top_k_per_article=TOP_K_PER_ARTICLE):\n",
    "    \n",
    "    normed_query = normalize_text(query)\n",
    "    query_tokens = normed_query.split()\n",
    "    \n",
    "    wiki_article_names = wikipedia.search(normed_query, results=10)\n",
    "    \n",
    "    fin_df = pd.DataFrame()\n",
    "    \n",
    "    for serp_pos, article_name in enumerate(wiki_article_names):\n",
    "        try:\n",
    "            wiki_page = wikipedia.page(article_name, auto_suggest=False)\n",
    "        except DisambiguationError as e:\n",
    "            print(\"Disambiguation error:\", article_name)\n",
    "            \n",
    "        title = wiki_page.title\n",
    "        content = wiki_page.content\n",
    "        \n",
    "        normed_title = normalize_text(title)\n",
    "        title_tokens = normed_title.split()\n",
    "\n",
    "        tokens_to_find = set(query_tokens) - set(title_tokens)\n",
    "        title_common_tokens = set(query_tokens) & set(title_tokens)\n",
    "\n",
    "        if len(title_common_tokens) == 0: # ignore if no query tokens are presented in title\n",
    "            continue\n",
    "        \n",
    "        result = get_suitable_paragraphs(query, tokens_to_find, content, serp_pos + 1, title, title_common_tokens)       \n",
    "\n",
    "        result_df = (\n",
    "            pd.DataFrame(result)\n",
    "            .sort_values(\n",
    "                by=[\"serp_position\", \"num_title_common_tokens\", \"num_paragraph_common_tokens\", \"paragraph_number_in_article\"],\n",
    "                ascending=[True, False, False, True]\n",
    "            )\n",
    "            .head(top_k_per_article)\n",
    "        )\n",
    "        fin_df = pd.concat((fin_df, result_df))\n",
    "        \n",
    "    if len(fin_df):\n",
    "        fin_df = (\n",
    "                pd.DataFrame(fin_df)\n",
    "                .sort_values(\n",
    "                    by=[\"serp_position\", \"num_title_common_tokens\", \"num_paragraph_common_tokens\", \"paragraph_number_in_article\"],\n",
    "                    ascending=[True, False, False, True]\n",
    "                )\n",
    "                .head(top_k_per_query)\n",
    "            )\n",
    "\n",
    "    return fin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d0e88e-dd47-4d39-a60c-62073299ab35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cd2035-4190-4c3b-9b84-6c57b61f4005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_source</th>\n",
       "      <th>query_id</th>\n",
       "      <th>description</th>\n",
       "      <th>query</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Can cranberries prevent urinary tract infections?</td>\n",
       "      <td>cranberries urinary tract infections</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>Can acupuncture be effective for people with e...</td>\n",
       "      <td>acupuncture epilepsy</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>Can acupuncture prevent migraines?</td>\n",
       "      <td>acupuncture migraine</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_source query_id                                        description  \\\n",
       "0        2019        1  Can cranberries prevent urinary tract infections?   \n",
       "1        2019        3  Can acupuncture be effective for people with e...   \n",
       "2        2019        5                 Can acupuncture prevent migraines?   \n",
       "\n",
       "                                  query  label  \n",
       "0  cranberries urinary tract infections    0.0  \n",
       "1                  acupuncture epilepsy    0.0  \n",
       "2                  acupuncture migraine    1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../data/data_to_process.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106b4ba-6cd5-4687-a3e7-5415175e0172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_result_query = pd.DataFrame()\n",
    "\n",
    "for _, info in pb(df.iterrows(), max_value=len(df)):\n",
    "    q = info.query\n",
    "    \n",
    "    res_df = get_paragraphs(q)\n",
    "    \n",
    "    if len(res_df):\n",
    "        res_df['query_id'] = info.query_id\n",
    "        res_df['data_source'] = info.data_source\n",
    "        res_df['label'] = info.label\n",
    "\n",
    "        final_result_query = pd.concat((final_result_query, res_df))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0850c533-c787-45dd-accd-3daefa463778",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_query.to_csv(\"../../../data/wikipedia_articles_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d8151-a57c-4335-b527-5f9fe9061320",
   "metadata": {},
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551ab5b-f6f7-4ea6-9241-dd518352ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_description = pd.DataFrame()\n",
    "\n",
    "for _, info in pb(df.iterrows(), max_value=len(df)):\n",
    "    q = info.description\n",
    "    \n",
    "    res_df = get_paragraphs(q)\n",
    "    \n",
    "    if len(res_df):\n",
    "        res_df['query_id'] = info.query_id\n",
    "        res_df['data_source'] = info.data_source\n",
    "        res_df['label'] = info.label\n",
    "\n",
    "        final_result_description = pd.concat((final_result_description, res_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ea7f88-79b3-43aa-bb04-e78823d6be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_query.to_csv(\"../../../data/wikipedia_articles_question.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142d9d8-9d49-49b6-82a2-998b382efb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
